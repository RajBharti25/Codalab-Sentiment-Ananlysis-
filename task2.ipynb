{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajBharti25/Codalab-Sentiment-Ananlysis-/blob/master/task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-OsIIFSBe_F",
        "colab_type": "code",
        "outputId": "471cdbbc-0173-4a91-e850-18e34f12c26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fya4u4czDFH4",
        "colab_type": "code",
        "outputId": "75638354-a80a-4d15-d8a7-f7e3253d9e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/CodaLab/working_directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU1TpEQhNjVC",
        "colab_type": "code",
        "outputId": "b8fd3dcb-8d0f-4c1b-94da-aa05e1cba790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd gdrive/My Drive/Colab Notebooks/CodaLab/working_directory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/CodaLab/working_directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMFz7bTONzlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "np.random.seed(0)\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense,Input,Dropout,LSTM,Activation,Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxSHT9isP0WJ",
        "colab_type": "code",
        "outputId": "e633d2ab-864b-4fca-9d10-8d09115b2892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "file=open('/content/gdrive/My Drive/Colab Notebooks/CodaLab/Data/EI-oc/EI-oc-En-train/EI-oc-En-anger-train.txt')\n",
        "f=file.read()\n",
        "Tweet=[]\n",
        "Class=[]\n",
        "lines=f.split('\\n')[1:]\n",
        "i=0\n",
        "for line in lines:\n",
        "  item=line.split('\\t')\n",
        "  if(len(item)<4):\n",
        "    #print(i)\n",
        "    i=i+1\n",
        "    continue\n",
        "  Tweet.append(item[1])\n",
        "  Class.append(item[3])\n",
        "for i in range(len(Class)):\n",
        "  Class[i]=int(str(Class[i])[0])\n",
        "Class=np.array(Class)\n",
        "Tweet=np.array(Tweet)\n",
        "file.close()\n",
        "for i in range(5):\n",
        "  print(Tweet[i])\n",
        "  print(Class[i])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@xandraaa5 @amayaallyn6 shut up hashtags are cool #offended\n",
            "2\n",
            "it makes me so fucking irate jesus. nobody is calling ppl who like hajime abusive stop with the strawmen lmao\n",
            "3\n",
            "Lol Adam the Bull with his fake outrage...\n",
            "1\n",
            "@THATSSHAWTYLO passed away early this morning in a fast and furious styled car crash as he was leaving an ATL strip club. That's rough stuff\n",
            "0\n",
            "@Kristiann1125 lol wow i was gonna say really?! haha have you seen chris or nah? you dont even snap me anymore dude!\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeMHcDnijYg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_value=[-0.12920076, -0.28866628, -0.01224866, -0.05676644, -0.20210965, -0.08389011,\n",
        "      0.33359843,  0.16045167,  0.03867431,  0.17833012,  0.04696583, -0.00285802,\n",
        "      0.29099807,  0.04613704, -0.20923874, -0.06613114, -0.06822549,  0.07665912,\n",
        "      0.3134014,   0.17848536, -0.1225775,  -0.09916984, -0.07495987,  0.06413227,\n",
        "      0.14441176,  0.60894334,  0.17463093,  0.05335403, -0.01273871,  0.03474107,\n",
        "      -0.8123879,  -0.04688699,  0.20193407,  0.2031118,  -0.03935686,  0.06967544,\n",
        "      -0.01553638, -0.03405238, -0.06528071,  0.12250231,  0.13991883, -0.17446303,\n",
        "      -0.08011883,  0.0849521,  -0.01041659, -0.13705009,  0.20127155,  0.10069408,\n",
        "       0.00653003,  0.01685157]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zljIzyv3QsBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "  with open(glove_file,'r') as f:\n",
        "    words=set()\n",
        "    words_to_vec_map={}\n",
        "    for line in f:\n",
        "      line =line.strip().split()\n",
        "      curr_word=line[0]\n",
        "      words.add(curr_word)\n",
        "      words_to_vec_map[curr_word]=np.array(line[1:], dtype=np.float64)\n",
        "    i=1\n",
        "    words_to_index={}\n",
        "    index_to_words={}\n",
        "    for w in sorted(words):\n",
        "      words_to_index[w]=i\n",
        "      index_to_words[i]=w\n",
        "      i=i+1\n",
        "    words=sorted(words)\n",
        "    words.append('<unk>')\n",
        "    words_to_index['<unk>']=i\n",
        "    index_to_words[i] = '<unk>'\n",
        "    words_to_vec_map['<unk>']=UNK_value\n",
        "\n",
        "  return words,words_to_index, index_to_words, words_to_vec_map\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2n3wvl_kFJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_set,word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(r'glove.6B.50d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R0IY0UrQ4z3",
        "colab_type": "code",
        "outputId": "39b91633-d44d-415c-deaa-08c60d9014bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if('<unk1>' in words_set):\n",
        "  print('true')\n",
        "else:\n",
        "  print('false')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrSRICeWj-J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_one_hot(Y,C):\n",
        "  Y = np.eye(C)[Y.reshape(-1)]\n",
        "  return Y\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CUVusz-nbnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train=to_categorical(Class, num_classes=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2CT-652Anid",
        "colab_type": "code",
        "outputId": "ae6fc7d7-4e30-45e3-f007-cb5ab09f2abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1701, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs162TKupDOx",
        "colab_type": "code",
        "outputId": "373f84e8-f091-4158-a44f-1397f4e484cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "word='king'\n",
        "idx = 289846\n",
        "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
        "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the index of king in the vocabulary is 207802\n",
            "the 289846th word in the vocabulary is potatos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewuiuQgTqAgZ",
        "colab_type": "code",
        "outputId": "77278310-0e9a-4659-82bb-d5cc097212a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "l=str(Tweet).strip().split()\n",
        "maxLen = len(max(l, key=len))\n",
        "maxLen"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K3vQhwpqidc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentence to indices function so that each word can be embedded with embedding vector\n",
        "def sentence_to_indices(X,word_to_index,max_len,words_set):\n",
        "  m=X.shape[0]\n",
        "  X_indices=np.zeros(shape=(m,max_len))\n",
        "  for i in range(m):\n",
        "    sentence=X[i]\n",
        "    sentence=re.sub(r'@(?i)[a-zA-Z0-9_]+','',sentence)\n",
        "    sentence=re.sub('[^a-zA-z0-9\\s]','',sentence)\n",
        "    words=sentence.lower().strip().split()\n",
        "    \n",
        "    j=0\n",
        "    for w in words:\n",
        "      if(w in words_set):\n",
        "        X_indices[i,j]=word_to_index[w]\n",
        "        j=j+1\n",
        "      else:\n",
        "        X_indices[i,j]=word_to_index['<unk>']\n",
        "        j=j+1\n",
        "  return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN-WSlmsARZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-5vkDCsqtHU",
        "colab_type": "code",
        "outputId": "05e64df4-7890-4a1d-fb93-df87e0901fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train=sentence_to_indices(Tweet,word_to_index,40,words_set)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Flags not at the start of the expression '@(?i)[a-zA-Z0-9_]+'\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meBQu6wVAS_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "943652f6-25a6-40da-f1c1-b216fe127155"
      },
      "source": [
        "file2=open('/content/gdrive/My Drive/Colab Notebooks/CodaLab/Data/EI-oc/2018-EI-oc-En-dev/2018-EI-oc-En-anger-dev.txt')\n",
        "f=file2.read()\n",
        "Tweet1=[]\n",
        "Class1=[]\n",
        "lines=f.split('\\n')[1:]\n",
        "i=0\n",
        "for line in lines:\n",
        "  item=line.split('\\t')\n",
        "  if(len(item)<4):\n",
        "    #print(i)\n",
        "    i=i+1\n",
        "    continue\n",
        "  Tweet1.append(item[1])\n",
        "  Class1.append(item[3])\n",
        "for i in range(len(Class1)):\n",
        "  Class1[i]=int(str(Class1[i])[0])\n",
        "Class1=np.array(Class1)\n",
        "Tweet1=np.array(Tweet1)\n",
        "file.close()\n",
        "for i in range(5):\n",
        "  print(Tweet1[i])\n",
        "  print(Class1[i])\n",
        "\n",
        "#xx_DEV,y_DEV\n",
        "X_dev=sentence_to_indices(Tweet1,word_to_index,40,words_set)\n",
        "Y_dev=to_categorical(Class1, num_classes=4)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'we need to do something. something must be done!!!!!'\\n\\nyour anxiety is amusing. nothing will be done. despair.\n",
            "1\n",
            "@Chan_lfc10 @paul_rule @Nuttall1878 @DeadlineDayLive @Everton We'd be fuming if the hijacked our £8m move for a relegated full back 😡\n",
            "2\n",
            "Caleb had a nightmare about zombies. I had a dream about freedom.......\n",
            "0\n",
            "#CNN really needs to get out of the #Propaganda Business.. 30 seconds on USN fallen Soldiers tragedy. Right back at spewing #hatred #POTUS\n",
            "2\n",
            "#dmme #kikme  #sext #horny  #ass #bbw  #naughty  #pussy #kik   #nudes  only  girls  😩 horny  #snap    jacobgigs\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Flags not at the start of the expression '@(?i)[a-zA-Z0-9_]+'\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISvKom9TjV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file3=open('/content/gdrive/My Drive/Colab Notebooks/CodaLab/Data/EI-oc/test-gold/2018-EI-oc-En-anger-test-gold.txt')\n",
        "f=file3.read()\n",
        "Tweet2=[]\n",
        "Class2=[]\n",
        "lines=f.split('\\n')[1:]\n",
        "i=0\n",
        "for line in lines:\n",
        "  item=line.split('\\t')\n",
        "  if(len(item)<4):\n",
        "    #print(i)\n",
        "    i=i+1\n",
        "    continue\n",
        "  Tweet2.append(item[1])\n",
        "  Class2.append(item[3])\n",
        "for i in range(len(Class2)):\n",
        "  Class2[i]=int(str(Class2[i])[0])\n",
        "Class2=np.array(Class2)\n",
        "Tweet2=np.array(Tweet2)\n",
        "file.close()\n",
        "for i in range(5):\n",
        "  print(Tweet2[i])\n",
        "  print(Class2[i])\n",
        "print('size of test data:',len(Tweet2))\n",
        "#xx_DEV,y_DEV\n",
        "X_test=sentence_to_indices(Tweet2,word_to_index,40,words_set)\n",
        "Y_test=to_categorical(Class2, num_classes=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8EGZdLEWUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train1=np.concatenate((X_train,X_test),axis=0)\n",
        "Y_train1=np.concatenate((Y_train,Y_test),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF8LYrATNjwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  pretrained_embedding_layer\n",
        "\n",
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    vocab_len = len(word_to_index) + 1                \n",
        "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]  \n",
        "    emb_matrix = np.zeros(shape=(vocab_len,emb_dim))\n",
        "  \n",
        "    for word, idx in word_to_index.items():\n",
        "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
        "\n",
        "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
        "    embedding_layer.build((None,)) \n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "    \n",
        "    return embedding_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2aae8DCNzuV",
        "colab_type": "code",
        "outputId": "3aff03f9-afef-463c-a3c8-ce8a4ceb6b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2725: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "weights[0][1][3] = -0.3403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6JZePrNAdgr",
        "colab_type": "code",
        "outputId": "5a8d7bfd-26ec-4dce-841b-fabf9ec80092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(X_train1.shape)\n",
        "print(Y_train1.shape)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2703, 40)\n",
            "(2703, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J9hCDbQrE72",
        "colab_type": "code",
        "outputId": "def524a9-0cb6-4734-9fd9-5fcd106df651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "input_shape=X_train.shape\n",
        "sentence_indices = Input(input_shape,dtype='int32')\n",
        "vocab_len=len(words_set)+1\n",
        "emb_dim=word_to_vec_map[\"cucumber\"].shape[0]\n",
        "#model = Sequential()\n",
        "#model.add(Embedding(vocab_len,25))\n",
        "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "# Propagate sentence_indices through your embedding layer\n",
        "# (See additional hints in the instructions).\n",
        "embeddings = embedding_layer(sentence_indices)    \n",
        "#model.add(LSTM(128, dropout =0.3, recurrent_dropout=0.3,return_sequences=True))\n",
        "X=LSTM(128, dropout =0.3, recurrent_dropout=0.3,return_sequences=True)(embeddings)\n",
        "#model.add(LSTM(128))\n",
        "X = LSTM(128, return_sequences=False)(X)\n",
        "#model.add(Dense(4, activation='softmax'))\n",
        "# try using different optimizers and different optimizer configs\n",
        "#adam = optimizers.Adam(lr=0.1)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "X = Dense(4)(X)\n",
        "    # Add a softmax activation\n",
        "X = Activation('softmax')(X)\n",
        "model = Model(inputs=sentence_indices, outputs=X)\n",
        "\"\"\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ninput_shape=X_train.shape\\nsentence_indices = Input(input_shape,dtype=\\'int32\\')\\nvocab_len=len(words_set)+1\\nemb_dim=word_to_vec_map[\"cucumber\"].shape[0]\\n#model = Sequential()\\n#model.add(Embedding(vocab_len,25))\\nembedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\\n# Propagate sentence_indices through your embedding layer\\n# (See additional hints in the instructions).\\nembeddings = embedding_layer(sentence_indices)    \\n#model.add(LSTM(128, dropout =0.3, recurrent_dropout=0.3,return_sequences=True))\\nX=LSTM(128, dropout =0.3, recurrent_dropout=0.3,return_sequences=True)(embeddings)\\n#model.add(LSTM(128))\\nX = LSTM(128, return_sequences=False)(X)\\n#model.add(Dense(4, activation=\\'softmax\\'))\\n# try using different optimizers and different optimizer configs\\n#adam = optimizers.Adam(lr=0.1)\\n#model.compile(loss=\\'categorical_crossentropy\\', optimizer=adam, metrics=[\\'accuracy\\'])\\nX = Dense(4)(X)\\n    # Add a softmax activation\\nX = Activation(\\'softmax\\')(X)\\nmodel = Model(inputs=sentence_indices, outputs=X)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIH8CW3OBLmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_Model(input_shape, word_to_vec_map, word_to_index):\n",
        "    \n",
        "    sentence_indices = Input(input_shape,dtype='int32')\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "    \n",
        "    embeddings = embedding_layer(sentence_indices)  \n",
        "    X = Bidirectional(LSTM(128, return_sequences=True))(embeddings)\n",
        "    # dropout with a probability of 0.3\n",
        "    X = Dropout(0.5)(X)\n",
        "    #  X trough another BiLSTM layer with 128-dimensional hidden state\n",
        "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
        "    # dropout with a probability of 0.2\n",
        "    X = Dropout(0.5)(X)\n",
        "    #  X through a Dense layer with 5 units\n",
        "    X = Dense(4)(X)\n",
        "    # softmax activation\n",
        "    X = Activation('softmax')(X)\n",
        "    \n",
        "    # Model instance which converts sentence_indices into X.\n",
        "    model = Model(inputs=sentence_indices, outputs=X)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBSem9qnBSND",
        "colab_type": "code",
        "outputId": "9d9f79fb-83f9-49c4-f20b-603b67069b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model1 = LSTM_Model((40,), word_to_vec_map, word_to_index)\n",
        "model1.summary()\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 40, 50)            20000100  \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 40, 256)           183296    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 40, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 1028      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 20,578,664\n",
            "Trainable params: 578,564\n",
            "Non-trainable params: 20,000,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5HVgjwDBboM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adam = optimizers.Adam(lr=0.1)\n",
        "checkpointer = ModelCheckpoint('best_weight_task2.hdf5', verbose=0, save_best_only=True)\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEr-u7kWBm9n",
        "colab_type": "code",
        "outputId": "937cf01c-1087-4468-e602-046704c1942d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1.fit(X_train1, Y_train1, validation_data = [X_dev,Y_dev], callbacks=[checkpointer], shuffle=True, epochs = 40, batch_size = 32)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2703 samples, validate on 388 samples\n",
            "Epoch 1/40\n",
            "2703/2703 [==============================] - 25s 9ms/step - loss: 1.1558 - acc: 0.4880 - val_loss: 1.1062 - val_acc: 0.5412\n",
            "Epoch 2/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 1.1098 - acc: 0.5165 - val_loss: 1.1215 - val_acc: 0.5284\n",
            "Epoch 3/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 1.0703 - acc: 0.5353 - val_loss: 1.1225 - val_acc: 0.5180\n",
            "Epoch 4/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 1.0210 - acc: 0.5542 - val_loss: 1.1712 - val_acc: 0.5155\n",
            "Epoch 5/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.9678 - acc: 0.5768 - val_loss: 1.1693 - val_acc: 0.5103\n",
            "Epoch 6/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.9410 - acc: 0.5934 - val_loss: 1.3588 - val_acc: 0.4407\n",
            "Epoch 7/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.8721 - acc: 0.6286 - val_loss: 1.2356 - val_acc: 0.5180\n",
            "Epoch 8/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.8062 - acc: 0.6722 - val_loss: 1.3142 - val_acc: 0.4433\n",
            "Epoch 9/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.7582 - acc: 0.6859 - val_loss: 1.3490 - val_acc: 0.4923\n",
            "Epoch 10/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.7121 - acc: 0.7048 - val_loss: 1.4926 - val_acc: 0.4871\n",
            "Epoch 11/40\n",
            "2703/2703 [==============================] - 20s 8ms/step - loss: 0.6445 - acc: 0.7429 - val_loss: 1.5354 - val_acc: 0.4588\n",
            "Epoch 12/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.5804 - acc: 0.7699 - val_loss: 1.6423 - val_acc: 0.4356\n",
            "Epoch 13/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.5284 - acc: 0.7876 - val_loss: 1.6803 - val_acc: 0.4588\n",
            "Epoch 14/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.4890 - acc: 0.8135 - val_loss: 1.6950 - val_acc: 0.4716\n",
            "Epoch 15/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.4547 - acc: 0.8217 - val_loss: 1.8806 - val_acc: 0.4562\n",
            "Epoch 16/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.3793 - acc: 0.8557 - val_loss: 2.0614 - val_acc: 0.4665\n",
            "Epoch 17/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.3199 - acc: 0.8757 - val_loss: 2.1075 - val_acc: 0.4536\n",
            "Epoch 18/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.3031 - acc: 0.8820 - val_loss: 2.3080 - val_acc: 0.4433\n",
            "Epoch 19/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.2672 - acc: 0.9038 - val_loss: 2.3876 - val_acc: 0.4356\n",
            "Epoch 20/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.2265 - acc: 0.9186 - val_loss: 2.4074 - val_acc: 0.4330\n",
            "Epoch 21/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.2261 - acc: 0.9160 - val_loss: 2.5777 - val_acc: 0.4433\n",
            "Epoch 22/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.2150 - acc: 0.9279 - val_loss: 2.4432 - val_acc: 0.4639\n",
            "Epoch 23/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1596 - acc: 0.9464 - val_loss: 2.7234 - val_acc: 0.4304\n",
            "Epoch 24/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.2231 - acc: 0.9223 - val_loss: 2.5639 - val_acc: 0.4923\n",
            "Epoch 25/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1286 - acc: 0.9600 - val_loss: 2.8420 - val_acc: 0.4278\n",
            "Epoch 26/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1365 - acc: 0.9541 - val_loss: 2.7282 - val_acc: 0.4820\n",
            "Epoch 27/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1205 - acc: 0.9634 - val_loss: 2.8120 - val_acc: 0.4613\n",
            "Epoch 28/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1381 - acc: 0.9552 - val_loss: 2.6969 - val_acc: 0.4794\n",
            "Epoch 29/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1172 - acc: 0.9615 - val_loss: 2.8925 - val_acc: 0.4691\n",
            "Epoch 30/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.0963 - acc: 0.9660 - val_loss: 2.9377 - val_acc: 0.4510\n",
            "Epoch 31/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1255 - acc: 0.9556 - val_loss: 3.3069 - val_acc: 0.4098\n",
            "Epoch 32/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.0887 - acc: 0.9674 - val_loss: 3.1276 - val_acc: 0.4459\n",
            "Epoch 33/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.0713 - acc: 0.9804 - val_loss: 3.2733 - val_acc: 0.4381\n",
            "Epoch 34/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.0773 - acc: 0.9763 - val_loss: 3.3858 - val_acc: 0.4124\n",
            "Epoch 35/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1238 - acc: 0.9567 - val_loss: 3.1457 - val_acc: 0.3686\n",
            "Epoch 36/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1166 - acc: 0.9589 - val_loss: 3.1855 - val_acc: 0.4149\n",
            "Epoch 37/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.1040 - acc: 0.9667 - val_loss: 3.2456 - val_acc: 0.4124\n",
            "Epoch 38/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.0732 - acc: 0.9774 - val_loss: 3.3390 - val_acc: 0.4485\n",
            "Epoch 39/40\n",
            "2703/2703 [==============================] - 20s 8ms/step - loss: 0.0837 - acc: 0.9697 - val_loss: 3.5515 - val_acc: 0.4149\n",
            "Epoch 40/40\n",
            "2703/2703 [==============================] - 21s 8ms/step - loss: 0.0988 - acc: 0.9663 - val_loss: 3.0433 - val_acc: 0.4562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffb1e510748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOr72OsuOWWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.load_weights('best_weight_task2.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exqJoWX2Bnp2",
        "colab_type": "code",
        "outputId": "b2da24aa-1a9c-4687-d241-7e8d3619ae31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss, acc = model1.evaluate(X_dev, Y_dev)\n",
        "print(\"Accuracy of the Classifier model on Dev data is:\",acc*100)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "388/388 [==============================] - 0s 1ms/step\n",
            "Accuracy of the Classifier model on Dev data is: 54.123711340206185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMSvZiOyTPKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}